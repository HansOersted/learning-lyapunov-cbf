
\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage[a4paper, margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{datetime}
\pagestyle{fancy}
\fancyhf{}
\rhead{Lyapunov Training Report}
\lhead{}
\rfoot{Page \thepage}

\title{Lyapunov Function Training Report}
\author{}
\date{\today\ at \currenttime}

\begin{document}
\maketitle
\thispagestyle{fancy}

\section*{1. Tracking Error History}
Tracking error ($e$) is the difference between the reference ($r$) and the actual value ($x$):
\begin{equation}
e = r - x.
\end{equation}

\indent The subsequent plot illustrates the historical tracking error data, which serves as input for the neural network.

\begin{center}
\includegraphics[width=0.85\textwidth]{tracking_error_history.pdf}
\end{center}

\section*{2. Training Summary}
Lyapunov candidate training completed with the following key observations:
\begin{itemize}
  \item  Loss is decreasing or non-increasing.
  \item  Final loss below threshold.
\end{itemize}

\begin{center}
\includegraphics[width=0.85\textwidth]{loss_history.pdf}
\end{center}

\section*{3. Final Lyapunov Form}
The Lyapunov function ($V$) is synthesized based on the Cholesky factorization:

\begin{equation}
V = 
\begin{bmatrix}
e & \dot{e}
\end{bmatrix}
A
\begin{bmatrix}
e \\
\dot{e}
\end{bmatrix},
\label{eq:lyapunov_definition}
\end{equation}

\begin{equation}
A = L L^\top,
\end{equation}
where $L$ is the Cholesky factor.

The final learned matrices:
\begin{align}
L &= \begin{bmatrix}
1.22 & 0.00 \\
0.79 & 0.64 \\
\end{bmatrix}, \\
A &= \begin{bmatrix}
1.49 & 0.96 \\
0.96 & 1.03 \\
\end{bmatrix}.
\end{align}

\section*{4. Lyapunov Surface}
The Lyapunov surface, Formula~\eqref{eq:lyapunov_definition}, is visualized in the following figure.
\begin{center}
\includegraphics[width=0.85\textwidth]{lyapunov_surface.pdf}
\end{center}

\section*{5. Final Constraint Inequality}
The final constraint inequality is given by:
\begin{equation}
\dot{V} + \lambda V \leq \epsilon,
\label{eq:constraint_definition}
\end{equation}
where $\lambda = 0.0$, $\epsilon = 0.0000$.

\section*{6. Constraint Curve}
The left side of Formula~\eqref{eq:constraint_definition} is depicted using all the below training data. The curve should stay beneath the threshold $\epsilon$.

\begin{center}
\includegraphics[width=0.85\textwidth]{training_constraint_curve.pdf}
\end{center}

\end{document}